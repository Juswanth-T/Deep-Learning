{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path='/content/drive/MyDrive/team8/task1/'"
      ],
      "metadata": {
        "id": "_pBZniTchEld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzHwoEcFdiMO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os, numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from numpy import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 32\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "id": "uu2vB3VVDzed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(path)"
      ],
      "metadata": {
        "id": "0QSYFXVKhl0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=pd.read_csv(path+'train_data.csv',header = None)\n",
        "y_train=pd.read_csv(path+'train_label.csv',header = None)\n",
        "X_test=pd.read_csv(path+'test_data.csv',header = None)\n",
        "y_test=pd.read_csv(path+'test_label.csv',header = None)\n",
        "X_valid=pd.read_csv(path+'val_data.csv',header = None)\n",
        "y_valid=pd.read_csv(path+'val_label.csv',header = None).iloc[:,-1]"
      ],
      "metadata": {
        "id": "8gc8thRIhoD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "44VXEN3sNLeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data = pd.concat([X_train, y_train], axis=1)\n",
        "shuffled_data = shuffle(combined_data)\n",
        "shuffled_data.reset_index(drop=True, inplace=True)\n",
        "X_train=shuffled_data.iloc[:, :-1]\n",
        "y_train=shuffled_data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "1O_UTvckyhEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid = torch.from_numpy(X_valid.values).float()\n",
        "y_valid = torch.from_numpy(y_valid.values).long()"
      ],
      "metadata": {
        "id": "c0wIwKqBE6JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.hl1=nn.Linear(36, 20)\n",
        "    self.hl2=nn.Linear(20, 10)\n",
        "    self.ol=nn.Linear(10, 5)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.hl1(x)\n",
        "    x=F.tanh(x)\n",
        "    x=self.hl2(x)\n",
        "    x=F.tanh(x)\n",
        "    return self.ol(x).reshape(-1, 5)"
      ],
      "metadata": {
        "id": "rU89B_Yldm9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conf_matrix(model):\n",
        "  with torch.no_grad():\n",
        "    y_pred=[]\n",
        "    y_true=[]\n",
        "    for i in range(len(X_train)):\n",
        "      X=torch.tensor(X_train.iloc[i], dtype=torch.float32)#, device='cuda')\n",
        "      y=torch.tensor(y_train.iloc[i], dtype=torch.float32)#, device='cuda')\n",
        "      y_hat=model(X)\n",
        "      y_l=y_hat.tolist()[0]\n",
        "      pred=y_l.index(max(y_l))\n",
        "      y_pred.append(pred)\n",
        "      y_true.append(y.item())\n",
        "    cf_train = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    y_pred=[]\n",
        "    y_true=[]\n",
        "    for i in range(len(X_test)):\n",
        "      X=torch.tensor(X_test.iloc[i], dtype=torch.float32)#, device='cuda')\n",
        "      y=torch.tensor(y_test.iloc[i], dtype=torch.float32)#, device='cuda')\n",
        "      y_hat=model(X)\n",
        "      y_l=y_hat.tolist()[0]\n",
        "      pred=y_l.index(max(y_l))\n",
        "      y_pred.append(pred)\n",
        "      y_true.append(y.item())\n",
        "    cf_test = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "  return cf_train, cf_test"
      ],
      "metadata": {
        "id": "zeCQWxz-s80B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weights initialization"
      ],
      "metadata": {
        "id": "1p6dq4N6AKte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(seed)\n",
        "weights_layer1 = random.normal(loc=0, scale=1/(36**0.5), size=(20, 36))\n",
        "weights_layer2 = random.normal(loc=0, scale=1/(20**0.5), size=(10, 20))\n",
        "weights_layer3 = random.normal(loc=0, scale=1/(10**0.5), size=(5, 10))\n",
        "\n",
        "weights_dict = {36:weights_layer1, 20:weights_layer2, 10:weights_layer3}"
      ],
      "metadata": {
        "id": "NeTRpxke7-6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Takes in a module and initializes all linear layers with weight\n",
        "      values taken from a normal distribution."
      ],
      "metadata": {
        "id": "6XsNpoQx6E4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Linear') != -1:  # Only for linear layers\n",
        "    y = m.in_features\n",
        "    m.weight.data = torch.tensor(weights_dict[y], dtype=torch.float32)\n",
        "    m.bias.data.fill_(torch.tensor(0, dtype=torch.float32))"
      ],
      "metadata": {
        "id": "iGYGsKn744Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "threshold = 0.002"
      ],
      "metadata": {
        "id": "C8v-tORZ5eVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer):\n",
        "  model.train()\n",
        "  delta_avg_loss=2*threshold\n",
        "  epoch=1\n",
        "  avg_error_dict = {}\n",
        "  prev_epoch_loss=float('inf')\n",
        "  validation_loss = {}\n",
        "  while abs(delta_avg_loss)>threshold:\n",
        "    epoch_loss=0\n",
        "    for i in range(len(X_train)):\n",
        "      X=torch.tensor(X_train.iloc[i], dtype=torch.float32)#.to('cuda')\n",
        "      y=torch.tensor(y_train.iloc[i], dtype=torch.float32)#.to('cuda')\n",
        "      y_hat=model(X)\n",
        "      loss=loss_func(y_hat, y.reshape(1).long())\n",
        "      loss.backward() # compute gradient of loss with respect to model parameter\n",
        "      optimizer.step() # Update the parameters\n",
        "      optimizer.zero_grad() # Assign zero to gradient\n",
        "      with torch.no_grad():\n",
        "        epoch_loss+=loss.item()\n",
        "        if i%100==0:\n",
        "          print(f'EPOCH: {epoch} LOSS: {loss.item()}')\n",
        "    with torch.no_grad():\n",
        "        y_hat_valid = model(X_valid)\n",
        "        valid_loss = loss_func(y_hat_valid, y_valid)\n",
        "        validation_loss.update({epoch:valid_loss})\n",
        "    avg_epoch_loss = epoch_loss/len(X_train)\n",
        "    print('\\n'+'-'*100+'\\n')\n",
        "    print(f'Total Loss: {epoch_loss}, Average Loss: {avg_epoch_loss} Average Validation Loss: {valid_loss}')\n",
        "    print('\\n'+'-'*100+'\\n')\n",
        "    delta_avg_loss = prev_epoch_loss-avg_epoch_loss\n",
        "    prev_epoch_loss = avg_epoch_loss\n",
        "    avg_error_dict.update({epoch:avg_epoch_loss})\n",
        "    epoch+=1\n",
        "  return avg_error_dict, validation_loss"
      ],
      "metadata": {
        "id": "qGsAVqfmr7l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delta"
      ],
      "metadata": {
        "id": "-tT32dZi6mGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net()\n",
        "model.to(torch.float32)\n",
        "model.apply(weights_init_normal)\n",
        "optimizer=optim.SGD(model.parameters(), lr=learning_rate)\n",
        "avg_error_dict, validation_loss = train(model, optimizer)"
      ],
      "metadata": {
        "id": "zR5_m6vNf5Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(map(str, list(avg_error_dict.keys()))), list(avg_error_dict.values()), label='Average training loss')\n",
        "plt.plot(list(map(str, list(validation_loss.keys()))), list(validation_loss.values()), label='Average validation loss')\n",
        "plt.xticks(list(map(str, list(avg_error_dict.keys())))[::3])\n",
        "plt.legend()\n",
        "plt.grid('true')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.title('Average Loss vs. Epochs for Delta optimizer')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mhK3srPUAzyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_train, cf_test = conf_matrix(model)\n",
        "sns.heatmap(cf_train, annot=True)\n",
        "plt.title('Confusion Matrix for Training Data')\n",
        "plt.show()\n",
        "plt.title('Confusion Matrix for Test Data')\n",
        "sns.heatmap(cf_test, annot=True)\n",
        "plt.show()\n",
        "\n",
        "# 49.4 %"
      ],
      "metadata": {
        "id": "uCLV55qXvCHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generalized Delta"
      ],
      "metadata": {
        "id": "tvZyPrbZ6qUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net()\n",
        "model.to(torch.float32)\n",
        "model.apply(weights_init_normal)\n",
        "th = 1e-4\n",
        "optimizer=optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "avg_error_dict, validation_loss = train(model, optimizer)"
      ],
      "metadata": {
        "id": "reT1OOrdf-Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(map(str, list(avg_error_dict.keys()))), list(avg_error_dict.values()), label='Average training loss')\n",
        "plt.plot(list(map(str, list(validation_loss.keys()))), list(validation_loss.values()), label='Average validation loss')\n",
        "plt.xticks(list(map(str, list(avg_error_dict.keys()))))\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.title('Average Loss vs. Epochs for Generalized Delta optimizer')\n",
        "plt.grid('true')"
      ],
      "metadata": {
        "id": "ado9kPryKHVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_train, cf_test = conf_matrix(model)\n",
        "sns.heatmap(cf_train, annot=True)\n",
        "plt.title('Confusion Matrix for Training Data')\n",
        "plt.show()\n",
        "plt.title('Confusion Matrix for Test Data')\n",
        "sns.heatmap(cf_test, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pblhm0t6vDNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaGrad"
      ],
      "metadata": {
        "id": "BI43EfrS6T0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net()\n",
        "model.to(torch.float32)\n",
        "model.apply(weights_init_normal)\n",
        "optimizer=optim.Adagrad(model.parameters(), lr=learning_rate)\n",
        "avg_error_dict, validation_loss = train(model, optimizer)"
      ],
      "metadata": {
        "id": "kTFejGmOwv6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.plot(list(map(str, list(avg_error_dict.keys()))), list(avg_error_dict.values()))\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Average Loss')\n",
        "# plt.title('Average Loss vs. Epochs for AdaGrad optimizer')"
      ],
      "metadata": {
        "id": "CsKaisiMcULo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(map(str, list(avg_error_dict.keys()))), list(avg_error_dict.values()), label='Average training loss')\n",
        "plt.plot(list(map(str, list(validation_loss.keys()))), list(validation_loss.values()), label='Average validation loss')\n",
        "plt.xticks(list(map(str, list(avg_error_dict.keys())))[::3])\n",
        "plt.legend()\n",
        "plt.grid('true')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.title('Average Loss vs. Epochs for AdaGrad')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TauHZxrMKOZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_train, cf_test = conf_matrix(model)\n",
        "sns.heatmap(cf_train, annot=True)\n",
        "plt.title('Confusion Matrix for Training Data')\n",
        "plt.show()\n",
        "plt.title('Confusion Matrix for Test Data')\n",
        "sns.heatmap(cf_test, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "luCtS3smu7VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSprop"
      ],
      "metadata": {
        "id": "t3YRsx3n6fBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net()\n",
        "model.to(torch.float32)\n",
        "model.apply(weights_init_normal)\n",
        "optimizer=optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "avg_error_dict, validation_loss = train(model, optimizer)"
      ],
      "metadata": {
        "id": "8TNsIdiC6hBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(map(str, list(avg_error_dict.keys()))), list(avg_error_dict.values()), label='Average training loss')\n",
        "plt.plot(list(map(str, list(validation_loss.keys()))), list(validation_loss.values()), label='Average validation loss')\n",
        "plt.xticks(list(map(str, list(avg_error_dict.keys()))))\n",
        "plt.legend()\n",
        "plt.grid('true')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.title('Average Loss vs. Epochs for RMSprop optimizer')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j73TlX5HOJ_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_train, cf_test = conf_matrix(model)\n",
        "sns.heatmap(cf_train, annot=True)\n",
        "plt.title('Confusion Matrix for Training Data')\n",
        "plt.show()\n",
        "plt.title('Confusion Matrix for Test Data')\n",
        "sns.heatmap(cf_test, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NsMKmL0mvAwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AdaM"
      ],
      "metadata": {
        "id": "rkdqN7186YN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Net()\n",
        "model.to(torch.float32)\n",
        "model.apply(weights_init_normal)\n",
        "optimizer=optim.Adam(model.parameters(), lr=learning_rate)\n",
        "avg_error_dict, validation_loss = train(model, optimizer)"
      ],
      "metadata": {
        "id": "PKaGxF0I6V68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(map(str, list(avg_error_dict.keys()))), list(avg_error_dict.values()), label='Average training loss')\n",
        "plt.plot(list(map(str, list(validation_loss.keys()))), list(validation_loss.values()), label='Average validation loss')\n",
        "plt.xticks(list(map(str, list(avg_error_dict.keys())))[::2])\n",
        "plt.legend()\n",
        "plt.grid('true')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Average Loss')\n",
        "plt.title('Average Loss vs. Epochs for AdaM optimizer')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OFfR7NfQPRxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_train, cf_test = conf_matrix(model)\n",
        "sns.heatmap(cf_train, annot=True)\n",
        "plt.title('Confusion Matrix for Training Data')\n",
        "plt.show()\n",
        "plt.title('Confusion Matrix for Test Data')\n",
        "sns.heatmap(cf_test, annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uAj4bwtCu-KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Q6jKXaOPrAJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}